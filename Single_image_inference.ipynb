{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qio32tYXxdk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "from PIL import Image, ImageFilter\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models, transforms\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def bicubic_downsample(input_path, output_path, scale=2):\n",
        "    \"\"\"\n",
        "    Downsamples an image using bicubic interpolation.\n",
        "\n",
        "    Args:\n",
        "        input_path (str): Path to the input high-resolution image.\n",
        "        output_path (str): Path to save the downsampled image.\n",
        "        scale (int): Downsampling factor (e.g., 2 means image size will be halved).\n",
        "    \"\"\"\n",
        "    # Open image\n",
        "    img = Image.open(input_path).convert(\"RGB\")\n",
        "    w, h = img.size\n",
        "\n",
        "    # Compute new size\n",
        "    new_w = w // scale\n",
        "    new_h = h // scale\n",
        "\n",
        "    # Bicubic downsampling\n",
        "    img_down = img.resize((new_w, new_h), Image.BICUBIC)\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "\n",
        "    # Save result\n",
        "    img_down.save(output_path)\n",
        "\n",
        "    print(f\"✅ Downsampled image saved at: {output_path}\")\n",
        "    print(f\"Original size: {w}x{h}, Downsampled size: {new_w}x{new_h}\")\n",
        "\n",
        "# -------------------------------\n",
        "# Example usage\n",
        "# -------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    input_image = \"/content/richard-avedon-marilyn-monroe-min-1.jpg\"      # path to original HR image\n",
        "    output_image = \"downsampled/sample_x2.jpg\"   # save path\n",
        "    scale_factor = 2                             # e.g., 2x downsample\n",
        "\n",
        "    bicubic_downsample(input_image, output_image, scale=scale_factor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT_5kAydHSEf",
        "outputId": "1dffd060-7204-49d4-dd0d-fc002ad0f424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Downsampled image saved at: downsampled/sample_x2.jpg\n",
            "Original size: 604x537, Downsampled size: 302x268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F # Import F for relu and interpolate\n",
        "from torchvision import transforms, models # Import models for VGG\n",
        "from PIL import Image, ImageFilter # Import ImageFilter for potential post-processing\n",
        "import os\n",
        "import glob # Import glob for finding files if needed later\n",
        "\n",
        "# ====================================\n",
        "# CONFIGURATION\n",
        "# ====================================\n",
        "MODEL_PATH = \"/content/tiny_espcn_celeba.pth\"   # Path to your trained model\n",
        "INPUT_IMAGE = \"/content/downsampled/sample_x2.jpg\"              # Low-resolution input image\n",
        "OUTPUT_IMAGE = \"/content/sample_sr_2.png\"          # Super-resolved output path\n",
        "UPSCALE_FACTOR = 2                              # Set same as training\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ====================================\n",
        "# MODEL DEFINITION (TinyESPCN Enhanced)\n",
        "# ====================================\n",
        "# Channel Attention module (copied from training code)\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channels, channels//reduction, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(channels//reduction, channels, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        b,c,_,_ = x.size()\n",
        "        y = self.avg_pool(x).view(b,c)\n",
        "        y = self.fc(y).view(b,c,1,1)\n",
        "        return x * y\n",
        "\n",
        "# TinyESPCN Enhanced Model (copied from training code)\n",
        "class TinyESPCNEnhanced(nn.Module):\n",
        "    def __init__(self, scale=2, use_attention=True):\n",
        "        super().__init__()\n",
        "        self.scale = scale\n",
        "        self.use_attention = use_attention\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3,64,7,1,3)\n",
        "        self.res_blocks = nn.Sequential(*[nn.Sequential(nn.Conv2d(64,64,3,1,1), nn.ReLU()) for _ in range(10)])\n",
        "        if use_attention:\n",
        "            self.attention = ChannelAttention(64)\n",
        "        self.conv2 = nn.Conv2d(64, 3*(scale**2), 3,1,1)\n",
        "        self.pixel_shuffle = nn.PixelShuffle(scale)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lr_input = x\n",
        "        x1 = F.relu(self.conv1(x))\n",
        "        x2 = self.res_blocks(x1)\n",
        "        if self.use_attention:\n",
        "            x2 = self.attention(x2)\n",
        "        x = self.pixel_shuffle(self.conv2(x2+x1))\n",
        "        lr_up = F.interpolate(lr_input, scale_factor=self.scale, mode='bicubic', align_corners=False)\n",
        "        return torch.clamp(x+lr_up,0,1)\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# LOAD MODEL\n",
        "# ====================================\n",
        "model = TinyESPCNEnhanced(scale=UPSCALE_FACTOR) # Use the Enhanced model definition\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
        "model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "# ====================================\n",
        "# TRANSFORMS\n",
        "# ====================================\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "to_pil = transforms.ToPILImage()\n",
        "\n",
        "# ====================================\n",
        "# LOAD INPUT IMAGE\n",
        "# ====================================\n",
        "image = Image.open(INPUT_IMAGE).convert(\"RGB\")\n",
        "input_tensor = transform(image).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "# ====================================\n",
        "# INFERENCE\n",
        "# ====================================\n",
        "with torch.no_grad():\n",
        "    output_tensor = model(input_tensor)\n",
        "\n",
        "output_tensor = torch.clamp(output_tensor.squeeze(0), 0, 1)\n",
        "output_image = to_pil(output_tensor.cpu())\n",
        "\n",
        "# ====================================\n",
        "# SAVE OUTPUT IMAGE\n",
        "# ====================================\n",
        "os.makedirs(os.path.dirname(OUTPUT_IMAGE), exist_ok=True)\n",
        "output_image.save(OUTPUT_IMAGE)\n",
        "print(f\"✅ Super-resolution complete! Saved at: {OUTPUT_IMAGE}\")\n",
        "\n",
        "#Optional display\n",
        "output_image.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtzwDTBBCn8Z",
        "outputId": "6dd59ca2-7314-4316-fced-5acd634b79a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Super-resolution complete! Saved at: /content/sample_sr_2.png\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}